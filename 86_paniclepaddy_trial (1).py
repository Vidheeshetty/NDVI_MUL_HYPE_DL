# -*- coding: utf-8 -*-
"""86_paniclepaddy_trial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-0m3HdOT8mfq2uIVpnSj0ZoBj_0AJnbQ
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!apt-get install -y unzip
!pip install rasterio
!pip install torch torchvision  # Just to ensure we have PyTorch
!pip install scikit-learn      # for optional clustering if needed

import os
import glob
import numpy as np
import rasterio
from rasterio.plot import show
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

# %matplotlib inline

!apt-get install unzip
zip_path = '/content/drive/MyDrive/Agri.zip'
output_path = '/content/drive/MyDrive'

!mkdir -p {output_path}  # Create the output directory if it doesn't exist
!unzip -q "{zip_path}" -d "{output_path}"

import zipfile
# Suppose your zipped data is in 'my_data.zip' somewhere
zip_path = "/content/drive/MyDrive/Agri.zip"   # change to your actual path
output_dir = "/content/data_unzipped"

os.makedirs(output_dir, exist_ok=True)

# Unzip
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(output_dir)

print("Data unzipped to:", output_dir)

import os

# Example: update this path to match your dataset
deep_dir_path = '/content/data_unzipped/Agri/Paddy/paddy_season4_RededgeMultispectral_20190917_05m/000'

os.listdir(deep_dir_path)

# Commented out IPython magic to ensure Python compatibility.
!pip install rasterio

import os
import numpy as np
import rasterio
from rasterio.plot import show
import matplotlib.pyplot as plt

# %matplotlib inline

def read_bands(directory, prefix='band', num_bands=5):
    """Reads band files from a directory and returns a stacked numpy array (bands, height, width)."""
    band_arrays = []
    for i in range(1, num_bands+1):
        band_path = os.path.join(directory, f'{prefix}{i}.tif')
        with rasterio.open(band_path) as src:
            band_arrays.append(src.read(1))  # read first (and only) band from each
    return np.stack(band_arrays, axis=0)  # shape: (5, H, W)

import os

all_files = os.listdir(deep_dir_path)
print(all_files)

import os

deep_dir_path = '/content/data_unzipped/Agri/Paddy/paddy_season4_RededgeMultispectral_20190917_05m/000'

all_files = [f for f in os.listdir(deep_dir_path) if f.endswith('.tif')]
all_files.sort()
print(all_files)

import re
from collections import defaultdict

grouped_files = defaultdict(list)

pattern = r"(IMG_\d+)_(\d+)\.tif"
# Explanation:
#  (IMG_\d+)  -> captures something like "IMG_0009"
#  _(\\d+)    -> captures the band number (1..5)
#  \.tif      -> ends with ".tif"

for filename in all_files:
    match = re.match(pattern, filename)
    if match:
        img_id = match.group(1)        # e.g. "IMG_0009"
        band_idx = match.group(2)      # e.g. "1", "2", ...
        grouped_files[img_id].append(filename)

# Check how files got grouped
for k, v in grouped_files.items():
    print(k, "->", v)

for img_id, files in grouped_files.items():
    # sort by the numeric portion of the filename
    # (which is captured as group(2) in the pattern above)
    grouped_files[img_id] = sorted(files, key=lambda f: int(re.match(pattern, f).group(2)))

# Now each group is sorted properly:
# IMG_0009 -> ['IMG_0009_1.tif', 'IMG_0009_2.tif', 'IMG_0009_3.tif', 'IMG_0009_4.tif', 'IMG_0009_5.tif']
# etc.

import rasterio
import numpy as np

def read_group_bands(directory, file_list):
    """
    Given a list of 5 .tif filenames, reads them all
    and stacks them as (bands, height, width).
    """
    band_arrays = []
    for tif_file in file_list:
        path = os.path.join(directory, tif_file)
        with rasterio.open(path) as src:
            band_arrays.append(src.read(1))  # read the single band

    return np.stack(band_arrays, axis=0)

# Example: loop through each group
for img_id, file_list in grouped_files.items():
    print(f"Reading {img_id} with files: {file_list}")
    band_stack = read_group_bands(deep_dir_path, file_list)
    print("Resulting shape:", band_stack.shape)
    # band_stack[0] = band 1
    # band_stack[1] = band 2
    # ...

def calculate_ndvi(bands, red_idx=2, nir_idx=4):
    """
    NDVI = (NIR - Red) / (NIR + Red)
    bands: shape (5, H, W)
    """
    red = bands[red_idx].astype(float)
    nir = bands[nir_idx].astype(float)
    with np.errstate(divide='ignore', invalid='ignore'):
        ndvi = (nir - red) / (nir + red)
        ndvi = np.nan_to_num(ndvi, nan=0.0, posinf=0.0, neginf=0.0)
    return ndvi

for img_id, file_list in grouped_files.items():
    band_stack = read_group_bands(deep_dir_path, file_list)
    ndvi = calculate_ndvi(band_stack, red_idx=2, nir_idx=4)
    print(f"{img_id} NDVI shape:", ndvi.shape)
    # Do something with the NDVI (plot, save, etc.)

# NDVI calculation
def calculate_ndvi(bands, red_idx=2, nir_idx=4):
    red = bands[red_idx].astype(float)
    nir = bands[nir_idx].astype(float)
    with np.errstate(divide='ignore', invalid='ignore'):
        ndvi = (nir - red) / (nir + red)
        ndvi = np.nan_to_num(ndvi, nan=0.0, posinf=0.0, neginf=0.0)
    return ndvi

# 3,4,5. Loop through groups, read, compute NDVI, etc.
for img_id, file_list in grouped_files.items():
    # Read bands into shape (5, H, W)
    bands = read_group_bands(deep_dir_path, file_list)

    # Suppose band order is:
    # 0: Blue, 1: Green, 2: Red, 3: RedEdge, 4: NIR
    ndvi_image = calculate_ndvi(bands, red_idx=2, nir_idx=4)

    # For demonstration, show the NDVI
    plt.figure(figsize=(6, 4))
    plt.title(f"{img_id} NDVI")
    plt.imshow(ndvi_image, cmap='RdYlGn')
    plt.colorbar(label='NDVI')
    plt.axis('off')
    plt.show()

def vegetation_mask(ndvi, threshold=0.6):
    """
    Returns a binary mask where pixels with NDVI >= threshold
    are considered vegetation (1), else non-vegetation (0).
    """
    mask = (ndvi >= threshold).astype(np.uint8)
    return mask

# Suppose ndvi_image is your NDVI array
veg_mask = vegetation_mask(ndvi_image, threshold=0.6)

import cv2

kernel = np.ones((3,3), np.uint8)
veg_mask_cleaned = cv2.morphologyEx(veg_mask, cv2.MORPH_CLOSE, kernel)

###########################
# STEP 3A: HELPER FUNCTIONS
###########################
import re
import cv2

def crop_black_borders(band_stack):
    """
    Crops out rows/columns where all bands are zero.
    band_stack shape: (bands, H, W)
    """
    non_zero_mask = np.any(band_stack != 0, axis=0)  # shape: (H, W)
    rows = np.any(non_zero_mask, axis=1)
    cols = np.any(non_zero_mask, axis=0)
    rmin, rmax = np.where(rows)[0][0], np.where(rows)[0][-1]
    cmin, cmax = np.where(cols)[0][0], np.where(cols)[0][-1]
    cropped_stack = band_stack[:, rmin:rmax+1, cmin:cmax+1]
    return cropped_stack

def calculate_ndvi(band_stack, red_idx=2, nir_idx=4):
    """
    NDVI = (NIR - RED) / (NIR + RED)
    band_stack shape: (5, H, W) for [Blue, Green, Red, RedEdge, NIR]
    """
    red = band_stack[red_idx].astype(float)
    nir = band_stack[nir_idx].astype(float)
    with np.errstate(divide='ignore', invalid='ignore'):
        ndvi = (nir - red) / (nir + red)
        ndvi = np.nan_to_num(ndvi, nan=0.0, posinf=0.0, neginf=0.0)
    return ndvi

###########################
# STEP 3B: GROUP BY PREFIX
###########################
all_tifs = sorted([f for f in os.listdir(deep_dir_path) if f.endswith('.tif')])

import re
from collections import defaultdict

pattern = r"(IMG_\d+)_(\d+)\.tif"
grouped_files = defaultdict(list)

for filename in all_tifs:
    match = re.match(pattern, filename)
    if match:
        img_id = match.group(1)    # e.g. "IMG_0009"
        grouped_files[img_id].append(filename)

# Sort each group by the numeric suffix (1..5)
for img_id, file_list in grouped_files.items():
    grouped_files[img_id] = sorted(file_list, key=lambda f: int(re.match(pattern, f).group(2)))

# Let's see how many sets we have
print("Number of image sets:", len(grouped_files))
for k, v in list(grouped_files.items())[:2]:
    print(k, "->", v)

###########################
# STEP 3C: PROCESS & SAVE
###########################
processed_dir = '/content/processed_data'
bands_dir = os.path.join(processed_dir, 'bands')
ndvi_dir  = os.path.join(processed_dir, 'ndvi')

os.makedirs(bands_dir, exist_ok=True)
os.makedirs(ndvi_dir, exist_ok=True)

def stack_and_save_5bands(img_id, file_list):
    """
    Reads the 5 .tif files, stacks them, crops black borders, calculates NDVI, and saves.
    """
    band_arrays = []
    for tif_file in file_list:
        path = os.path.join(deep_dir_path, tif_file)
        with rasterio.open(path) as src:
            band_arrays.append(src.read(1))  # shape: (H, W)

    band_stack = np.stack(band_arrays, axis=0)  # shape: (5, H, W)
    cropped_stack = crop_black_borders(band_stack)
    ndvi_image = calculate_ndvi(cropped_stack, red_idx=2, nir_idx=4)

    # Save stacked bands
    out_bands_path = os.path.join(bands_dir, f'{img_id}_bands.tif')

    # Copy metadata from the first band (just for georeferencing if needed)
    first_band_path = os.path.join(deep_dir_path, file_list[0])
    with rasterio.open(first_band_path) as src_ref:
        meta = src_ref.meta.copy()

    meta.update({
        'count': 5,  # 5 bands
        'width': cropped_stack.shape[2],
        'height': cropped_stack.shape[1],
        'dtype': 'float32'
    })

    with rasterio.open(out_bands_path, 'w', **meta) as dst:
        for i in range(5):
            dst.write(cropped_stack[i].astype(np.float32), i+1)

    # Save NDVI
    out_ndvi_path = os.path.join(ndvi_dir, f'{img_id}_ndvi.tif')
    meta.update({
        'count': 1,
        'dtype': 'float32'
    })
    with rasterio.open(out_ndvi_path, 'w', **meta) as dst:
        dst.write(ndvi_image.astype(np.float32), 1)

    return cropped_stack, ndvi_image

# Process each group
for img_id, files in grouped_files.items():
    cropped_bands, ndvi_img = stack_and_save_5bands(img_id, files)

print("Processing complete. Stacked 5-band and NDVI saved.")

###########################
# STEP 3D: QUICK PLOT
###########################
# Pick one example
sample_id = list(grouped_files.keys())[0]
sample_bands_path = os.path.join(bands_dir, f'{sample_id}_bands.tif')
sample_ndvi_path  = os.path.join(ndvi_dir,  f'{sample_id}_ndvi.tif')

with rasterio.open(sample_bands_path) as src:
    sample_bands = src.read()  # shape: (5, H, W)
with rasterio.open(sample_ndvi_path) as src:
    sample_ndvi = src.read(1)  # shape: (H, W)

plt.figure(figsize=(12,4))
for i in range(5):
    plt.subplot(1,6,i+1)
    plt.imshow(sample_bands[i], cmap='gray')
    plt.title(f'Band {i+1}')
    plt.axis('off')

plt.subplot(1,6,6)
plt.imshow(sample_ndvi, cmap='RdYlGn')
plt.title('NDVI')
plt.axis('off')
plt.tight_layout()
plt.show()

###########################
# STEP 4A: CREATE PSEUDO-MASKS
###########################
masks_dir = os.path.join(processed_dir, 'masks')
os.makedirs(masks_dir, exist_ok=True)

def create_pseudo_panicle_mask(band_stack, ndvi_image,
                               ndvi_min=0.2, ndvi_max=0.6,
                               rededge_thresh=300):
    """
    band_stack: shape (5, H, W) with [B, G, R, RE, NIR]
    ndvi_image: shape (H, W)
    ndvi_min, ndvi_max: NDVI range to consider potential 'panicle'
    rededge_thresh: threshold in the Red Edge band (raw units, adjust as needed)
    """
    # 1) NDVI range
    ndvi_mask = (ndvi_image >= ndvi_min) & (ndvi_image <= ndvi_max)

    # 2) RedEdge threshold
    # band_stack[3] is Red Edge if our band order is [0:Blue,1:Green,2:Red,3:RE,4:NIR]
    re_mask = (band_stack[3] >= rededge_thresh)

    combined = ndvi_mask & re_mask
    mask = combined.astype(np.uint8)

    # 3) Morphological cleanup (optional)
    kernel = np.ones((3,3), np.uint8)
    mask_cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

    return mask_cleaned

# We'll loop through the processed bands & NDVI images to create pseudo masks
band_files = sorted(glob.glob(os.path.join(bands_dir, '*_bands.tif')))
print("Found band files for pseudo-masking:", len(band_files))

for band_path in band_files:
    filename = os.path.basename(band_path)
    img_id = filename.replace('_bands.tif','')

    ndvi_path = os.path.join(ndvi_dir, f'{img_id}_ndvi.tif')
    mask_out_path = os.path.join(masks_dir, f'{img_id}_mask.tif')

    if not os.path.exists(ndvi_path):
        continue  # skip if NDVI not found

    with rasterio.open(band_path) as src_b:
        bstack = src_b.read()  # shape: (5, H, W)
        meta_b = src_b.meta.copy()
    with rasterio.open(ndvi_path) as src_n:
        ndvi_img = src_n.read(1)
        meta_n = src_n.meta.copy()

    # Create pseudo mask
    pseudo_mask = create_pseudo_panicle_mask(
        bstack, ndvi_img, ndvi_min=0.2, ndvi_max=0.6, rededge_thresh=300
    )

    # Save mask as TIF
    meta_b.update({
        'count': 1,
        'dtype': 'uint8'
    })
    with rasterio.open(mask_out_path, 'w', **meta_b) as dst:
        dst.write(pseudo_mask, 1)

print("Pseudo masks created in:", masks_dir)

###########################
# STEP 4B: PLOT PSEUDO-MASK
###########################
sample_mask_path = os.path.join(masks_dir, f'{sample_id}_mask.tif')
if os.path.exists(sample_mask_path):
    with rasterio.open(sample_mask_path) as src_m:
        pseudo_mask = src_m.read(1)

    plt.figure(figsize=(12,4))

    plt.subplot(1,3,1)
    plt.title("Red Edge band")
    plt.imshow(sample_bands[3], cmap='gray')
    plt.axis('off')

    plt.subplot(1,3,2)
    plt.title("NDVI")
    plt.imshow(sample_ndvi, cmap='RdYlGn', vmin=-1, vmax=1)
    plt.axis('off')

    plt.subplot(1,3,3)
    plt.title("Pseudo Panicle Mask")
    plt.imshow(pseudo_mask, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()
else:
    print("Pseudo-mask for sample not found!")

###########################
# STEP 5A: BUILD DATASET
###########################

class PaddyPseudoDataset(Dataset):
    def __init__(self, data_list):
        """
        data_list: list of tuples (band_path, ndvi_path, mask_path)
        """
        self.data_list = data_list

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        band_path, ndvi_path, mask_path = self.data_list[idx]

        with rasterio.open(band_path) as src_b:
            bands_5 = src_b.read().astype(np.float32)  # shape: (5, H, W)
        with rasterio.open(ndvi_path) as src_n:
            ndvi_img = src_n.read(1).astype(np.float32)  # shape: (H, W)
        with rasterio.open(mask_path) as src_m:
            mask_img = src_m.read(1).astype(np.float32)  # shape: (H, W)

        # Expand NDVI to (1, H, W)
        ndvi_img = np.expand_dims(ndvi_img, axis=0)

        # Combine to (6, H, W)
        image_6 = np.concatenate([bands_5, ndvi_img], axis=0)

        # Expand mask to (1, H, W)
        mask_img = np.expand_dims(mask_img, axis=0)

        # Convert to torch
        image_6 = torch.from_numpy(image_6)
        mask_img = torch.from_numpy(mask_img)

        return image_6, mask_img

# Collect all matched files
band_paths = sorted(glob.glob(os.path.join(bands_dir, '*_bands.tif')))
data_list = []
for bp in band_paths:
    filename = os.path.basename(bp)
    img_id = filename.replace('_bands.tif','')
    np_path = os.path.join(ndvi_dir, f'{img_id}_ndvi.tif')
    mk_path = os.path.join(masks_dir, f'{img_id}_mask.tif')
    if os.path.exists(np_path) and os.path.exists(mk_path):
        data_list.append((bp, np_path, mk_path))

print("Total dataset samples:", len(data_list))

# Split train/val/test
trainval_list, test_list = train_test_split(data_list, test_size=0.2, random_state=42)
train_list, val_list = train_test_split(trainval_list, test_size=0.25, random_state=42)
# => 60% train, 20% val, 20% test

train_dataset = PaddyPseudoDataset(train_list)
val_dataset   = PaddyPseudoDataset(val_list)
test_dataset  = PaddyPseudoDataset(test_list)

print("Train:", len(train_dataset), "Val:", len(val_dataset), "Test:", len(test_dataset))

###########################
# STEP 5B: UNET MODEL
###########################
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_channels=6, out_channels=1):
        super().__init__()
        self.dc1 = DoubleConv(in_channels, 64)
        self.dc2 = DoubleConv(64, 128)
        self.dc3 = DoubleConv(128, 256)
        self.dc4 = DoubleConv(256, 512)
        self.pool = nn.MaxPool2d(2)

        self.bottleneck = DoubleConv(512, 1024)

        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dc_up4 = DoubleConv(1024, 512)

        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dc_up3 = DoubleConv(512, 256)

        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dc_up2 = DoubleConv(256, 128)

        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dc_up1 = DoubleConv(128, 64)

        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)

    def forward(self, x):
        # Encoder
        c1 = self.dc1(x)
        p1 = self.pool(c1)
        c2 = self.dc2(p1)
        p2 = self.pool(c2)
        c3 = self.dc3(p2)
        p3 = self.pool(c3)
        c4 = self.dc4(p3)
        p4 = self.pool(c4)

        # Bottleneck
        cb = self.bottleneck(p4)

        # Decoder
        u4 = self.up4(cb)
        cat4 = torch.cat([u4, c4], dim=1)
        c4_up = self.dc_up4(cat4)

        u3 = self.up3(c4_up)
        cat3 = torch.cat([u3, c3], dim=1)
        c3_up = self.dc_up3(cat3)

        u2 = self.up2(c3_up)
        cat2 = torch.cat([u2, c2], dim=1)
        c2_up = self.dc_up2(cat2)

        u1 = self.up1(c2_up)
        cat1 = torch.cat([u1, c1], dim=1)
        c1_up = self.dc_up1(cat1)

        out = self.out_conv(c1_up)
        return out  # shape: (batch, 1, H, W)

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import gc
import matplotlib.pyplot as plt

###########################
# (A) Define DoubleConv and UNet
###########################
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.conv(x)

class UNet(nn.Module):
    def __init__(self, in_channels=6, out_channels=1):
        """
        in_channels = 6 => 5 bands + NDVI
        out_channels = 1 => binary segmentation
        """
        super().__init__()
        self.dc1 = DoubleConv(in_channels, 64)
        self.dc2 = DoubleConv(64, 128)
        self.dc3 = DoubleConv(128, 256)
        self.dc4 = DoubleConv(256, 512)
        self.pool = nn.MaxPool2d(2)

        self.bottleneck = DoubleConv(512, 1024)

        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dc_up4 = DoubleConv(1024, 512)

        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dc_up3 = DoubleConv(512, 256)

        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dc_up2 = DoubleConv(256, 128)

        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dc_up1 = DoubleConv(128, 64)

        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)

    def forward(self, x):
        # Encoder
        c1 = self.dc1(x)
        p1 = self.pool(c1)
        c2 = self.dc2(p1)
        p2 = self.pool(c2)
        c3 = self.dc3(p2)
        p3 = self.pool(c3)
        c4 = self.dc4(p3)
        p4 = self.pool(c4)

        # Bottleneck
        cb = self.bottleneck(p4)

        # Decoder
        u4 = self.up4(cb)
        cat4 = torch.cat([u4, c4], dim=1)
        c4_up = self.dc_up4(cat4)

        u3 = self.up3(c4_up)
        cat3 = torch.cat([u3, c3], dim=1)
        c3_up = self.dc_up3(cat3)

        u2 = self.up2(c3_up)
        cat2 = torch.cat([u2, c2], dim=1)
        c2_up = self.dc_up2(cat2)

        u1 = self.up1(c2_up)
        cat1 = torch.cat([u1, c1], dim=1)
        c1_up = self.dc_up1(cat1)

        out = self.out_conv(c1_up)
        return out

###########################
# (B) Dice Coefficient
###########################
def dice_coeff(pred, target, smooth=1e-5):
    """
    pred, target: (N, 1, H, W)
    Apply sigmoid to `pred`, threshold at 0.5, then compute Dice.
    """
    pred_bin = (torch.sigmoid(pred) > 0.5).float()
    intersection = (pred_bin * target).sum(dim=(1,2,3))
    union = pred_bin.sum(dim=(1,2,3)) + target.sum(dim=(1,2,3))
    dice = (2.0 * intersection + smooth) / (union + smooth)
    return dice.mean()

###########################
# (C) Train & Validate Functions
###########################
def train_one_epoch(model, loader, optimizer, criterion):
    model.train()
    epoch_loss = 0.0
    epoch_dice = 0.0

    for images, masks in loader:
        # Forward
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)

        # Backward
        loss.backward()
        optimizer.step()

        # Metrics
        epoch_loss += loss.item()
        epoch_dice += dice_coeff(outputs, masks).item()

        # Memory cleanup
        del images, masks, outputs, loss
        gc.collect()

    return epoch_loss / len(loader), epoch_dice / len(loader)

def validate_one_epoch(model, loader, criterion):
    model.eval()
    val_loss = 0.0
    val_dice = 0.0

    with torch.no_grad():
        for images, masks in loader:
            outputs = model(images)
            loss = criterion(outputs, masks)

            val_loss += loss.item()
            val_dice += dice_coeff(outputs, masks).item()

            # Memory cleanup
            del images, masks, outputs, loss
            gc.collect()

    return val_loss / len(loader), val_dice / len(loader)

###########################
# (D) Instantiate Datasets & Loaders
###########################
# We assume you already have:
#   train_dataset, val_dataset
# each created from your custom code or from steps 5B and earlier.

# Key memory-saving changes:
#   - batch_size=2 (or 1)
#   - num_workers=0
#   - no device references => CPU only
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
val_loader   = DataLoader(val_dataset,   batch_size=8, shuffle=False, num_workers=0)
test_loader   = DataLoader(test_dataset,   batch_size=4, shuffle=False, num_workers=0)

###########################
# (E) Define Model, Loss, Optimizer
###########################
model = UNet(in_channels=6, out_channels=1)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)

###########################
# (F) Training Loop
###########################
num_epochs = 25

train_loss_history = []
train_dice_history = []
val_loss_history   = []
val_dice_history   = []

for epoch in range(num_epochs):
    train_loss, train_dice = train_one_epoch(model, train_loader, optimizer, criterion)
    val_loss, val_dice = validate_one_epoch(model, val_loader, criterion)

    # Record metrics
    train_loss_history.append(train_loss)
    train_dice_history.append(train_dice)
    val_loss_history.append(val_loss)
    val_dice_history.append(val_dice)

    # Print status
    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f} | "
          f"Val Loss: {val_loss:.4f}, Val Dice: {val_dice:.4f}")

# Plot final learning curves
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(train_loss_history, label='Train Loss')
plt.plot(val_loss_history,   label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.subplot(1,2,2)
plt.plot(train_dice_history, label='Train Dice')
plt.plot(val_dice_history,   label='Val Dice')
plt.xlabel('Epoch')
plt.ylabel('Dice')
plt.title('Dice Coefficient over Epochs')
plt.legend()

plt.show()

# Plot final learning curves
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(train_loss_history, label='Train Loss')
plt.plot(val_loss_history,   label='Val Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Loss over Epochs')
plt.legend()

plt.subplot(1,2,2)
plt.plot(train_dice_history, label='Train Dice')
plt.plot(val_dice_history,   label='Val Dice')
plt.xlabel('Epoch')
plt.ylabel('Dice')
plt.title('Dice Coefficient over Epochs')
plt.legend()

plt.show()

test_loss = 0.0
test_dice = 0.0
model.eval()
with torch.no_grad():
    for images, masks in test_loader:
        outputs = model(images)
        loss = criterion(outputs, masks)
        test_loss += loss.item()
        test_dice += dice_coeff(outputs, masks).item()

        del images, masks, outputs, loss
        gc.collect()

test_loss /= len(test_loader)
test_dice /= len(test_loader)
print(f"Test Loss: {test_loss:.4f}, Test Dice: {test_dice:.4f}")

import random

n_samples_to_show = 3
model.eval()
indices = random.sample(range(len(test_dataset)), n_samples_to_show)

plt.figure(figsize=(12, 4*n_samples_to_show))
for i, idx in enumerate(indices):
    image_6, mask_gt = test_dataset[idx]  # shape (6, H, W), (1, H, W)
    # Convert to batch dimension
    image_6 = image_6.unsqueeze(0)

    with torch.no_grad():
        pred = model(image_6)  # (1, 1, H, W)
    pred_sigmoid = torch.sigmoid(pred)
    pred_bin = (pred_sigmoid > 0.5).float()

    # Convert to numpy
    pred_bin_np = pred_bin.squeeze().numpy()
    mask_gt_np = mask_gt.squeeze().numpy()
    ndvi_np = image_6.squeeze()[5].numpy()  # 6th channel is NDVI if your band order is [0..4=5bands,5=NDVI]

    plt.subplot(n_samples_to_show, 3, i*3 + 1)
    plt.title("NDVI Channel")
    plt.imshow(ndvi_np, cmap='RdYlGn')
    plt.axis('off')

    plt.subplot(n_samples_to_show, 3, i*3 + 2)
    plt.title("Ground Truth Mask")
    plt.imshow(mask_gt_np, cmap='gray')
    plt.axis('off')

    plt.subplot(n_samples_to_show, 3, i*3 + 3)
    plt.title("Predicted Mask")
    plt.imshow(pred_bin_np, cmap='gray')
    plt.axis('off')

plt.tight_layout()
plt.show()

# Assuming 'model' is your trained PyTorch model
torch.save(model.state_dict(), 'paniclepaddy86.pth')